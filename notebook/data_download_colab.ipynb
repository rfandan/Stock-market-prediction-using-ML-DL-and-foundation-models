{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Data Ingestion & Preprocessing Pipeline\n",
    "\n",
    "This notebook serves as the entry point for the project's data lifecycle. It performs the following steps:\n",
    "1. **Download**: Fetches historical stock and crypto data using `yfinance`.\n",
    "2. **Raw Storage**: Minimizes memory usage with `float32` and saves the raw state to Parquet.\n",
    "3. **Preprocessing**: Aligns trading days, computes features (lags, volatility, etc.), and prepares a target-ready panel data.\n",
    "4. **Processed Storage**: Saves the final engineered dataset for Model training.\n",
    "\n",
    "**Note for GitHub Users**: Run this notebook once to populate the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "START_DATE  = \"2010-01-01\"\n",
    "END_DATE    = \"2024-12-31\"\n",
    "ROLLING_WIN = 20\n",
    "\n",
    "# 12 tickers: 6 sectors + market ETF + crypto\n",
    "TICKERS = [\n",
    "    \"AAPL\", \"MSFT\", \"NVDA\",       # Tech\n",
    "    \"JPM\",  \"GS\",                  # Finance\n",
    "    \"JNJ\",  \"UNH\",                 # Healthcare\n",
    "    \"KO\",   \"MCD\",                 # Consumer\n",
    "    \"XOM\",                         # Energy\n",
    "    \"SPY\",                         # Market ETF (feature only)\n",
    "    \"BTC-USD\",                     # Crypto\n",
    "]\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download_markdown",
   "metadata": {},
   "source": [
    "## 1. Download & Save Raw Data\n",
    "We download the data and immediately cast numeric columns to `float32` to save 50% memory. We save this to `data/raw/stock_data_raw.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dict = {}\n",
    "for ticker in tqdm(TICKERS, desc=\"Downloading\"):\n",
    "    df = yf.download(\n",
    "        ticker, start=START_DATE, end=END_DATE,\n",
    "        interval=\"1d\", auto_adjust=False, progress=False,\n",
    "    )\n",
    "    if df.empty:\n",
    "        print(f\"  ⚠ {ticker}: empty — skipped\")\n",
    "        continue\n",
    "    \n",
    "    # Handle MultiIndex columns from newer yfinance versions\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df = df.droplevel(1, axis=1)\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.index.name = \"date\"\n",
    "    \n",
    "    # Cast to float32 for memory efficiency\n",
    "    float_cols = df.select_dtypes(include=['float']).columns\n",
    "    df[float_cols] = df[float_cols].astype('float32')\n",
    "    \n",
    "    raw_dict[ticker] = df\n",
    "\n",
    "print(f\"  ✓ {len(raw_dict)}/{len(TICKERS)} tickers downloaded\")\n",
    "\n",
    "# Save individual raw files (optional) or combine them\n",
    "# For simplicity, we save a combined raw panel\n",
    "raw_panel = pd.concat([df.assign(ticker=t) for t, df in raw_dict.items()])\n",
    "raw_panel.to_parquet(\"../data/raw/stock_data_raw.parquet\", index=True)\n",
    "print(\"  ✓ Raw data saved to data/raw/stock_data_raw.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering & Preprocessing\n",
    "We apply the logic from `EDA.ipynb` to create the final training dataset, aligning common trading days across all tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align Dates\n",
    "common_dates = sorted(set.intersection(*(set(d.index) for d in raw_dict.values())))\n",
    "aligned = {t: d.loc[common_dates].copy() for t, d in raw_dict.items()}\n",
    "print(f\"  ✓ {len(common_dates)} common trading days\")\n",
    "\n",
    "pieces = []\n",
    "for ticker, df in aligned.items():\n",
    "    d = df.copy()\n",
    "\n",
    "    # Target: today's log return\n",
    "    d[\"log_return\"] = np.log(d[\"adj close\"] / d[\"adj close\"].shift(1))\n",
    "\n",
    "    # Lagged returns\n",
    "    d[\"ret_lag1\"] = d[\"log_return\"].shift(1)\n",
    "    d[\"ret_lag2\"] = d[\"log_return\"].shift(2)\n",
    "    d[\"ret_lag5\"] = d[\"log_return\"].shift(5)\n",
    "\n",
    "    # 20-day rolling volatility\n",
    "    d[\"roll_vol\"] = d[\"log_return\"].rolling(ROLLING_WIN).std().shift(1)\n",
    "\n",
    "    # Normalized high-low range\n",
    "    d[\"range_norm\"] = ((d[\"high\"] - d[\"low\"]) / d[\"close\"]).shift(1)\n",
    "\n",
    "    # Volume z-score\n",
    "    v_mu  = d[\"volume\"].rolling(ROLLING_WIN).mean()\n",
    "    v_sig = d[\"volume\"].rolling(ROLLING_WIN).std()\n",
    "    d[\"vol_zscore\"] = ((d[\"volume\"] - v_mu) / v_sig).shift(1)\n",
    "\n",
    "    d[\"ticker\"] = ticker\n",
    "    pieces.append(d)\n",
    "\n",
    "panel = pd.concat(pieces).reset_index().set_index([\"date\", \"ticker\"]).sort_index()\n",
    "\n",
    "# Market return (SPY)\n",
    "if \"SPY\" in raw_dict:\n",
    "    spy_lr = (\n",
    "        panel.xs(\"SPY\", level=\"ticker\")[\"log_return\"]\n",
    "        .shift(1)\n",
    "        .rename(\"mkt_return\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    panel = (\n",
    "        panel.reset_index()\n",
    "        .merge(spy_lr, on=\"date\", how=\"left\")\n",
    "        .set_index([\"date\", \"ticker\"])\n",
    "    )\n",
    "\n",
    "panel.dropna(inplace=True)\n",
    "\n",
    "# Cast final features to float32\n",
    "panel = panel.astype({col: 'float32' for col in panel.select_dtypes('float64').columns})\n",
    "\n",
    "panel.to_parquet(\"../data/processed/stock_data_processed.parquet\", index=True)\n",
    "print(f\"  ✓ Processed panel shape: {panel.shape}\")\n",
    "print(\"  ✓ Processed data saved to data/processed/stock_data_processed.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
