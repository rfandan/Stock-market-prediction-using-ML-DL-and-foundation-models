{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Data Ingestion & Master Feature Store\n",
                "\n",
                "This notebook serves as the entry point for the project's data lifecycle. It performs the following steps:\n",
                "1. **Download**: Fetches historical stock and crypto data using `yfinance`.\n",
                "2. **Raw Storage**: Minimizes memory usage with `float32` and saves the raw state to Parquet.\n",
                "3. **Universal Feature Engineering**: Computes all features required for Stages 1 through 7, including:\n",
                "    - Lagged returns (Classical ML)\n",
                "    - Intraday OHLCV features (Deep Learning/Transformers)\n",
                "    - Rolling volatility & volume z-scores (Probabilistic/Amazon Chronos)\n",
                "4. **Processed Storage**: Saves the final engineeered dataset to `data/processed/stock_data_processed.parquet`.\n",
                "\n",
                "**Note for GitHub Users**: Run this notebook once to populate the `data/` directory before running any subsequent Stage notebooks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import yfinance as yf\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "from tqdm import tqdm\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# =============================================================================\n",
                "# Configuration\n",
                "# =============================================================================\n",
                "START_DATE  = \"2010-01-01\"\n",
                "END_DATE    = \"2024-12-31\"\n",
                "ROLLING_WIN = 20\n",
                "\n",
                "# 12 tickers: 6 sectors + market ETF + crypto\n",
                "TICKERS = [\n",
                "    \"AAPL\", \"MSFT\", \"NVDA\",       # Tech\n",
                "    \"JPM\",  \"GS\",                  # Finance\n",
                "    \"JNJ\",  \"UNH\",                 # Healthcare\n",
                "    \"KO\",   \"MCD\",                 # Consumer\n",
                "    \"XOM\",                         # Energy\n",
                "    \"SPY\",                         # Market ETF (feature only)\n",
                "    \"BTC-USD\",                     # Crypto\n",
                "]\n",
                "\n",
                "# Ensure directories exist\n",
                "os.makedirs(\"../data/raw\", exist_ok=True)\n",
                "os.makedirs(\"../data/processed\", exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "download_markdown",
            "metadata": {},
            "source": [
                "## 1. Download & Save Raw Data\n",
                "We download the data and immediately cast numeric columns to `float32`. We save the combined panel to `data/raw/stock_data_raw.parquet`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "download_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "raw_dict = {}\n",
                "for ticker in tqdm(TICKERS, desc=\"Downloading\"):\n",
                "    df = yf.download(\n",
                "        ticker, start=START_DATE, end=END_DATE,\n",
                "        interval=\"1d\", auto_adjust=False, progress=False,\n",
                "    )\n",
                "    if df.empty:\n",
                "        print(f\"  ⚠ {ticker}: empty — skipped\")\n",
                "        continue\n",
                "    \n",
                "    # Handle MultiIndex columns from newer yfinance versions\n",
                "    if isinstance(df.columns, pd.MultiIndex):\n",
                "        df = df.droplevel(1, axis=1)\n",
                "    \n",
                "    df.columns = df.columns.str.lower()\n",
                "    df.index.name = \"date\"\n",
                "    \n",
                "    # Cast to float32 for memory efficiency\n",
                "    float_cols = df.select_dtypes(include=['float', 'int']).columns\n",
                "    df[float_cols] = df[float_cols].astype('float32')\n",
                "    \n",
                "    raw_dict[ticker] = df\n",
                "\n",
                "print(f\"  ✓ {len(raw_dict)}/{len(TICKERS)} tickers downloaded\")\n",
                "\n",
                "raw_panel = pd.concat([df.assign(ticker=t) for t, df in raw_dict.items()])\n",
                "raw_panel.to_parquet(\"../data/raw/stock_data_raw.parquet\", index=True)\n",
                "print(\"  ✓ Raw data saved to data/raw/stock_data_raw.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feature_markdown",
            "metadata": {},
            "source": [
                "## 2. Universal Feature Engineering\n",
                "We compute a wide array of features to satisfy the requirements of all modeling stages (Baselines, LSTM, Transformers, Probabilistic, and Latent Analysis)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Align Dates (Common Trading Days)\n",
                "common_dates = sorted(set.intersection(*(set(d.index) for d in raw_dict.values())))\n",
                "aligned = {t: d.loc[common_dates].copy() for t, d in raw_dict.items()}\n",
                "print(f\"  ✓ {len(common_dates)} common trading days\")\n",
                "\n",
                "pieces = []\n",
                "for ticker, df in aligned.items():\n",
                "    d = df.copy()\n",
                "\n",
                "    # --- Block A: Target & Lagged Returns (Classical ML) ---\n",
                "    d[\"log_return\"] = np.log(d[\"adj close\"] / d[\"adj close\"].shift(1))\n",
                "    d[\"ret_lag1\"] = d[\"log_return\"].shift(1)\n",
                "    d[\"ret_lag2\"] = d[\"log_return\"].shift(2)\n",
                "    d[\"ret_lag5\"] = d[\"log_return\"].shift(5)\n",
                "\n",
                "    # --- Block B: Intraday & OHLCV Features (DL & Transformers) ---\n",
                "    d[\"oc_return\"] = (d[\"close\"] - d[\"open\"]) / d[\"open\"]\n",
                "    d[\"hl_range\"]  = (d[\"high\"] - d[\"low\"]) / d[\"close\"]\n",
                "    d[\"close_pos\"] = (d[\"close\"] - d[\"low\"]) / (d[\"high\"] - d[\"low\"] + 1e-8)\n",
                "    d[\"log_vol\"]   = np.log1p(d[\"volume\"])\n",
                "    d[\"vol_change\"] = np.log((d[\"volume\"] + 1) / (d[\"volume\"].shift(1) + 1))\n",
                "\n",
                "    # --- Block C: Rolling Statistics (Risk & Uncertainty) ---\n",
                "    d[\"roll_vol\"] = d[\"log_return\"].rolling(ROLLING_WIN).std().shift(1)\n",
                "    d[\"range_norm\"] = d[\"hl_range\"].rolling(ROLLING_WIN).mean().shift(1)\n",
                "    \n",
                "    # Volume z-score\n",
                "    v_mu  = d[\"log_vol\"].rolling(ROLLING_WIN).mean()\n",
                "    v_sig = d[\"log_vol\"].rolling(ROLLING_WIN).std()\n",
                "    d[\"vol_zscore\"] = ((d[\"log_vol\" ] - v_mu) / (v_sig + 1e-8)).shift(1)\n",
                "\n",
                "    d[\"ticker\"] = ticker\n",
                "    pieces.append(d)\n",
                "\n",
                "panel = pd.concat(pieces).reset_index().set_index([\"date\", \"ticker\"]).sort_index()\n",
                "\n",
                "# --- Block D: Market Alignment (SPY Return) ---\n",
                "if \"SPY\" in raw_dict:\n",
                "    spy_lr = (\n",
                "        panel.xs(\"SPY\", level=\"ticker\")[\"log_return\"]\n",
                "        .shift(1)\n",
                "        .rename(\"mkt_return\")\n",
                "        .reset_index()\n",
                "    )\n",
                "    panel = (\n",
                "        panel.reset_index()\n",
                "        .merge(spy_lr, on=\"date\", how=\"left\")\n",
                "        .set_index([\"date\", \"ticker\"])\n",
                "    )\n",
                "\n",
                "panel.dropna(inplace=True)\n",
                "\n",
                "# Final memory optimization\n",
                "float64_cols = panel.select_dtypes(include=['float64']).columns\n",
                "panel[float64_cols] = panel[float64_cols].astype('float32')\n",
                "\n",
                "panel.to_parquet(\"../data/processed/stock_data_processed.parquet\", index=True)\n",
                "print(f\"  ✓ Final Master Panel shape: {panel.shape}\")\n",
                "print(\"  ✓ Master features saved to data/processed/stock_data_processed.parquet\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}