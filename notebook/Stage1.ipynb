{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "883cf0aa",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.ensemble import HistGradientBoostingRegressor\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
                "from statsmodels.tsa.arima.model import ARIMA\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0478ae86",
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "Stage 1: Baselines & Classical ML\n",
                "=============================================================================\n",
                "Predict next-day log return using pre-processed panel data.\n",
                "Models: Persistence, Rolling Mean, Linear Regression, Gradient Boosting, ARIMA.\n",
                "\"\"\"\n",
                "\n",
                "# =============================================================================\n",
                "# 1. Load Processed Data\n",
                "# =============================================================================\n",
                "DATA_PATH = \"../data/processed/stock_data_processed.parquet\"\n",
                "\n",
                "if not os.path.exists(DATA_PATH):\n",
                "    raise FileNotFoundError(f\"Processed data not found at {DATA_PATH}. Please run data_download_colab.ipynb first.\")\n",
                "\n",
                "panel = pd.read_parquet(DATA_PATH)\n",
                "print(f\"  ✓ Loaded panel data with shape: {panel.shape}\")\n",
                "print(f\"  ✓ Date range: {panel.index.get_level_values('date').min()} to {panel.index.get_level_values('date').max()}\")\n",
                "\n",
                "# =============================================================================\n",
                "# 2. Configuration & Helper Functions\n",
                "# =============================================================================\n",
                "TRAIN_RATIO = 0.8\n",
                "ROLLING_WIN = 20\n",
                "FEATURE_COLS = [\n",
                "    \"ret_lag1\", \"ret_lag2\", \"ret_lag5\",\n",
                "    \"roll_vol\", \"range_norm\", \"vol_zscore\", \"mkt_return\",\n",
                "]\n",
                "\n",
                "def compute_metrics(y_true, y_pred):\n",
                "    \"\"\"Return MAE, RMSE, and directional accuracy (zeros excluded).\"\"\"\n",
                "    yt = np.asarray(y_true, dtype=float)\n",
                "    yp = np.asarray(y_pred, dtype=float)\n",
                "    mae  = mean_absolute_error(yt, yp)\n",
                "    rmse = np.sqrt(mean_squared_error(yt, yp))\n",
                "    mask = yt != 0\n",
                "    dacc = (\n",
                "        np.mean(np.sign(yt[mask]) == np.sign(yp[mask]))\n",
                "        if mask.any() else np.nan\n",
                "    )\n",
                "    return mae, rmse, dacc\n",
                "\n",
                "def fit_best_arima(y_train, max_p=3, max_q=3):\n",
                "    \"\"\"Grid-search ARIMA(p,0,q) by AIC. Returns best fitted model or None.\"\"\"\n",
                "    best_aic, best_fit = np.inf, None\n",
                "    for p in range(max_p + 1):\n",
                "        for q in range(max_q + 1):\n",
                "            if p == 0 and q == 0: continue\n",
                "            try:\n",
                "                fit = ARIMA(y_train, order=(p, 0, q)).fit()\n",
                "                if fit.aic < best_aic:\n",
                "                    best_aic, best_fit = fit.aic, fit\n",
                "            except Exception: continue\n",
                "    return best_fit\n",
                "\n",
                "# =============================================================================\n",
                "# 3. Model Evaluation\n",
                "# =============================================================================\n",
                "# SPY excluded as prediction target (mkt_return would be its own lagged return)\n",
                "eval_tickers = [\n",
                "    t for t in panel.index.get_level_values(\"ticker\").unique() if t != \"SPY\"\n",
                "]\n",
                "\n",
                "results = []\n",
                "\n",
                "for ticker in tqdm(eval_tickers, desc=\"Evaluating Models\"):\n",
                "    tk = panel.xs(ticker, level=\"ticker\")\n",
                "    if len(tk) < 100: continue\n",
                "\n",
                "    X, y = tk[FEATURE_COLS], tk[\"log_return\"]\n",
                "    n    = int(len(X) * TRAIN_RATIO)\n",
                "    Xtr, Xte = X.iloc[:n], X.iloc[n:]\n",
                "    ytr, yte = y.iloc[:n], y.iloc[n:]\n",
                "\n",
                "    preds = {}\n",
                "    \n",
                "    # Baseline — persistence (yesterday's return)\n",
                "    preds[\"Persistence\"] = tk[\"ret_lag1\"].loc[yte.index]\n",
                "\n",
                "    # Baseline — 20-day rolling mean (lagged by 1)\n",
                "    preds[\"Rolling Mean\"] = (\n",
                "        tk[\"log_return\"].rolling(ROLLING_WIN).mean().shift(1).loc[yte.index]\n",
                "    )\n",
                "\n",
                "    # Linear Regression\n",
                "    lr = LinearRegression().fit(Xtr, ytr)\n",
                "    preds[\"Linear Reg\"] = pd.Series(lr.predict(Xte), index=yte.index)\n",
                "\n",
                "    # Gradient Boosting\n",
                "    hgb = HistGradientBoostingRegressor(max_iter=200, random_state=42)\n",
                "    hgb.fit(Xtr, ytr)\n",
                "    preds[\"HistGB\"] = pd.Series(hgb.predict(Xte), index=yte.index)\n",
                "\n",
                "    # ARIMA — single fit, multi-step forecast\n",
                "    arima_fit = fit_best_arima(ytr)\n",
                "    if arima_fit is not None:\n",
                "        preds[\"ARIMA\"] = pd.Series(\n",
                "            arima_fit.forecast(steps=len(yte)).values, index=yte.index\n",
                "        )\n",
                "    else:\n",
                "        preds[\"ARIMA\"] = pd.Series(0.0, index=yte.index)\n",
                "\n",
                "    # Record metrics\n",
                "    for name, yp in preds.items():\n",
                "        mae, rmse, dacc = compute_metrics(yte, yp)\n",
                "        results.append(dict(\n",
                "            Ticker=ticker, Model=name,\n",
                "            MAE=round(mae, 6), RMSE=round(rmse, 6), DirAcc=round(dacc, 4),\n",
                "        ))\n",
                "\n",
                "# =============================================================================\n",
                "# 4. Results & Visualization\n",
                "# =============================================================================\n",
                "res = pd.DataFrame(results)\n",
                "\n",
                "# Aggregate summary\n",
                "summary = res.groupby(\"Model\")[[\"MAE\", \"RMSE\", \"DirAcc\"]].agg([\"mean\", \"std\"]).round(4)\n",
                "print(\"\\n\" + \"=\" * 65)\n",
                "print(\"  MODEL COMPARISON  (mean ± std across tickers)\")\n",
                "print(\"=\" * 65)\n",
                "print(summary)\n",
                "\n",
                "# Best model per ticker\n",
                "best = res.loc[res.groupby(\"Ticker\")[\"RMSE\"].idxmin()]\n",
                "print(\"\\n\" + \"=\" * 65)\n",
                "print(\"  BEST MODEL PER TICKER  (lowest RMSE)\")\n",
                "print(\"=\" * 65)\n",
                "print(best[[\"Ticker\", \"Model\", \"RMSE\", \"DirAcc\"]].to_string(index=False))\n",
                "\n",
                "# Plotting\n",
                "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
                "for ax, col, title in zip(\n",
                "    axes, [\"MAE\", \"RMSE\", \"DirAcc\"], \n",
                "    [\"Mean Absolute Error ↓\", \"Root Mean Squared Error ↓\", \"Directional Accuracy ↑\"]\n",
                "):\n",
                "    means = res.groupby(\"Model\")[col].mean().sort_values(ascending=(col != \"DirAcc\"))\n",
                "    means.plot.barh(ax=ax, color=\"steelblue\", edgecolor=\"black\")\n",
                "    ax.set_title(title)\n",
                "    ax.set_xlabel(col)\n",
                "\n",
                "plt.suptitle(\"Stage 1 — Baseline & Classical ML (Processed Data)\", fontsize=14, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
