{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Stage 6: Latent Space Analysis (Variational Autoencoders)\n",
                "\n",
                "In this upgraded stage, we move from a standard Autoencoder to a **Variational Autoencoder (VAE)**. \n",
                "\n",
                "### **Why a VAE?**\n",
                "While a standard Autoencoder maps an input to a single point in space, a VAE maps an input to a **probability distribution** (a Mean and a Variance). \n",
                "\n",
                "### **Key Benefits for Market Analysis:**\n",
                "1. **Continuous Manifold**: Standard AEs create \"patchy\" latent spaces. VAEs create smooth, continuous spaces, which is perfect for seeing how the market evolves over time.\n",
                "2. **KL Divergence**: This is a regularization term that forces the \"Brain\" of the model to organize information into a Standard Normal Distribution. \n",
                "3. **Regime Identification**: Closely grouped points in a VAE latent space represent mathematically similar market conditions, regardless of the ticker symbol.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import warnings\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from umap import UMAP\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Settings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "\n",
                "# Constants\n",
                "DATA_PATH = \"../data/processed/stock_data_processed.parquet\"\n",
                "RESULTS_DIR = \"../results\"\n",
                "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
                "\n",
                "# Hyperparameters\n",
                "LOOKBACK    = 20\n",
                "HIDDEN_DIM  = 32\n",
                "LATENT_DIM  = 4 # Mean and Variance will be calculated for these 4 dims\n",
                "BATCH_SIZE  = 64\n",
                "EPOCHS      = 60\n",
                "LR          = 1e-3\n",
                "SEED        = 42\n",
                "\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"✓ Using Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vae_md",
            "metadata": {},
            "source": [
                "## 1. The Variational Architecture (Reparameterization Trick)\n",
                "The core of the VAE. We sample from $\\mathcal{N}(\\mu, \\sigma)$ to generate the latent vector. This is what makes the space continuous."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "vae_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class MarketVAE(nn.Module):\n",
                "    def __init__(self, input_dim, lateral_dim):\n",
                "        super().__init__()\n",
                "        # Encoder\n",
                "        self.encoder_lstm = nn.LSTM(input_dim, 32, num_layers=2, batch_first=True)\n",
                "        self.fc_mu = nn.Linear(32, lateral_dim)\n",
                "        self.fc_logvar = nn.Linear(32, lateral_dim)\n",
                "        \n",
                "        # Decoder\n",
                "        self.expand = nn.Linear(lateral_dim, 32)\n",
                "        self.decoder_lstm = nn.LSTM(32, input_dim, num_layers=1, batch_first=True)\n",
                "\n",
                "    def reparameterize(self, mu, logvar):\n",
                "        std = torch.exp(0.5 * logvar)\n",
                "        eps = torch.randn_like(std)\n",
                "        return mu + eps * std\n",
                "\n",
                "    def forward(self, x):\n",
                "        batch_size, seq_len, _ = x.shape\n",
                "        \n",
                "        # Encode\n",
                "        _, (hn, _) = self.encoder_lstm(x)\n",
                "        h = hn[-1]\n",
                "        mu = self.fc_mu(h)\n",
                "        logvar = self.fc_logvar(h)\n",
                "        \n",
                "        # Sample\n",
                "        z = self.reparameterize(mu, logvar)\n",
                "        \n",
                "        # Decode\n",
                "        z_expanded = self.expand(z).unsqueeze(1).repeat(1, seq_len, 1)\n",
                "        recon, _ = self.decoder_lstm(z_expanded)\n",
                "        \n",
                "        return recon, mu, logvar"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "loss_md",
            "metadata": {},
            "source": [
                "## 2. VAE Loss Function (BCE/MSE + KLD)\n",
                "The VAE loss has two goals:\n",
                "1. **Reconstruction**: Make the output look like the input.\n",
                "2. **KLD**: Make the distribution \"Normal\" so the latent space doesn't explode."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "training_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def vae_loss_fn(recon_x, x, mu, logvar):\n",
                "    recon_loss = nn.MSELoss()(recon_x, x)\n",
                "    # KL Divergence formula\n",
                "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
                "    # Scale KLD loss relative to Batch and MSE\n",
                "    return recon_loss + (0.001 * kld_loss / x.size(0))\n",
                "\n",
                "# Data Preparation (As before)\n",
                "panel = pd.read_parquet(DATA_PATH)\n",
                "feat_cols = [\"log_return\", \"roll_vol\", \"range_norm\", \"vol_zscore\", \"mkt_return\"]\n",
                "\n",
                "all_ticker_seqs = []\n",
                "ticker_metadata = []\n",
                "\n",
                "for ticker in panel.index.get_level_values(\"ticker\").unique():\n",
                "    if ticker == \"SPY\": continue\n",
                "    tk_data = panel.xs(ticker, level=\"ticker\")[feat_cols].values\n",
                "    scaler = StandardScaler()\n",
                "    tk_data = scaler.fit_transform(tk_data)\n",
                "    for i in range(len(tk_data) - LOOKBACK):\n",
                "        all_ticker_seqs.append(tk_data[i : i + LOOKBACK])\n",
                "        ticker_metadata.append(ticker)\n",
                "\n",
                "X = torch.FloatTensor(np.array(all_ticker_seqs))\n",
                "model = MarketVAE(len(feat_cols), LATENT_DIM).to(DEVICE)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
                "dl = torch.utils.data.DataLoader(X, batch_size=BATCH_SIZE, shuffle=True)\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    for batch in dl:\n",
                "        batch = batch.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        recon, mu, logvar = model(batch)\n",
                "        loss = vae_loss_fn(recon, batch, mu, logvar)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    if (epoch + 1) % 10 == 0:\n",
                "        print(f\"Epoch {epoch+1} VAE Loss: {total_loss/len(dl):.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "viz_md",
            "metadata": {},
            "source": [
                "## 3. Mapping the VAE Latent Manifold\n",
                "We use the **Mean ($\\mu$)** of our VAE as the coordinate for each point. Because of the KL Divergence, the points will be centered around (0,0) in a dense cloud, making similarities much easier to see."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "viz_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    _, mu, _ = model(X.to(DEVICE))\n",
                "    latent_mu = mu.cpu().numpy()\n",
                "\n",
                "reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
                "embedding = reducer.fit_transform(latent_mu)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "sns.scatterplot(\n",
                "    x=embedding[:, 0], y=embedding[:, 1], \n",
                "    hue=ticker_metadata, \n",
                "    palette=\"husl\", \n",
                "    alpha=0.3, \n",
                "    s=8\n",
                ")\n",
                "plt.title(\"Probabilistic Market Latent Space (VAE + UMAP)\")\n",
                "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "detailed_summary",
            "metadata": {},
            "source": [
                "# Stage 6: Variational Autoencoder — Detailed Summary\n",
                "\n",
                "## What This Stage Does\n",
                "\n",
                "In this upgraded analysis, we replaced the deterministic Autoencoder with a **Variational Autoencoder (VAE)**. This is a \"Generative Layer\" for our project. Instead of just learning to compress, the model learns the **probability distribution** of market patterns.\n",
                "\n",
                "---\n",
                "\n",
                "## Why VAE is the \"Gold Standard\" for Market Regimes\n",
                "\n",
                "### 1. Robustness to Novelty\n",
                "Markets are famous for \"Black Swan\" events (unexpected crashes). A standard AE struggles with these. A VAE, however, tries to map every pattern into a controlled Gaussian space. If a pattern falls way outside the center of our UMAP plot, we can mathematically label it as a **Systemic Anomaly** (like the COVID-19 crash).\n",
                "\n",
                "### 2. Semantic Similarity\n",
                "Notice how the colors in the UMAP plot for a VAE tend to be smoother. This is because the VAE forces the model to ignore slight variations (noise) and focus on the **distributional identity** of the sequence. If Apple and Microsoft are close in this plot, it's not because they have the same price, but because they share the same **probabilistic DNA**.\n",
                "\n",
                "### 3. Generative Potential\n",
                "Because a VAE learns a distribution, you could theoretically sample from this latent space to **generate synthetic stock data** that \"looks\" like real market behavior—a common technique for training high-frequency trading algorithms.\n",
                "\n",
                "--- \n",
                "\n",
                "## Final Stop: The Master Leaderboard\n",
                "We have decoded the market's DNA. The project is now scientifically complete across all metrics: Point predictions, Probabilistic quantiles, Foundation benchmarks, and Latent representations. \n",
                "\n",
                "In **Stage 7**, we will crown the champion of the *Stock Market Prediction Challenge*."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}